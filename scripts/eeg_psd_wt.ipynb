{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Cleaning and Power Spectral Density Extraction Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Jupyter Notebook walks through the steps used to filter noise and identify and remove artifact-heavy segments and extract the power spectral density from scalp EEG. The functions here are the basis of the work in \"Quantitative EEG Spectral Features Differentiate Genetic Epilepsies and Predict Neurologic Outcomes\" by Galer et al. The file used here is a deidentified EEG from our control cohort from an individual approximetely 12.4 years of age. It has been converted to a fif file to ensure deidentification.\n",
    "#### The example data can be downloaded via the link: https://upenn.box.com/v/galerqeegcntrleg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import our custom function library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read eeg file\n",
    "### The pipeline typically works with EDF, but to ensure deidentification we use a fif file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/galerp/Documents/manuscripts/QEEG/EEG_Python/\"\n",
    "fif_file = \"P591_2017_07_15.fif\"\n",
    "\n",
    "raw = mne.io.read_raw_fif(file_path+fif_file, preload=True)\n",
    "\n",
    "# Load the data\n",
    "raw.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check length of EEG and crop if over limit\n",
    "### Most standard outpatient EEG in our cohorts are 20-40 minutes in length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Maximum duration in seconds (4 hours)\n",
    "max_duration = 4 * 3600 + 0.1\n",
    "\n",
    "# Get the duration of the recording\n",
    "recording_duration = raw.times[-1]\n",
    "\n",
    "print(\"Recording duration: \", recording_duration/60 , \" minutes\")\n",
    "\n",
    "# Crop the recording if it is longer than 4 hours\n",
    "if recording_duration > max_duration:\n",
    "    print(\"Recording duration is longer than 4 hours. Cropping the recording.\")\n",
    "    raw.crop(tmax=max_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check sampling frequency\n",
    "### Most standard outpatient EEG in our cohorts are 256Hz. The lowest in the cohort is 200Hz, so all EEGs are downsampled to 200Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target sampling frequency\n",
    "target_sf = 200\n",
    "# Get the sampling frequency of the data\n",
    "sf = raw.info['sfreq']\n",
    "\n",
    "if sf != target_sf:\n",
    "    print(\"Resampling the data to \", target_sf, \" Hz.\")\n",
    "    if sf > target_sf:\n",
    "        # Apply notch filter to remove power line noise and its harmonics\n",
    "        notch_harmonics = generate_harmonics(60, sf)\n",
    "        rawraw = raw.copy().notch_filter(freqs=notch_harmonics)\n",
    "\n",
    "        # Apply a low-pass filter to prevent aliasing\n",
    "        # Define the low-pass filter cutoff as just below half the target sampling frequency (Nyquist frequency)\n",
    "        low_pass = target_sf / 2 - 5  # 95 Hz if target is 200 Hz\n",
    "\n",
    "        # Apply a low-pass filter to prevent aliasing\n",
    "        rawraw.filter(l_freq=None, h_freq=low_pass, method='iir')\n",
    "\n",
    "        # Resample the data to the target sampling frequency\n",
    "        rawraw.resample(sfreq=target_sf)\n",
    "else:\n",
    "    # Apply notch filter to remove power line noise and its harmonics\n",
    "    notch_harmonics = generate_harmonics(60, sf)\n",
    "    rawraw = raw.copy().notch_filter(freqs=notch_harmonics)\n",
    "\n",
    "# Set the new sampling frequency\n",
    "sf = target_sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Volts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_volts = rawraw.apply_function(lambda x: x * 1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Montage\n",
    "### In the past few years some EEGs are collected in a slightly higher density Modified Combinatorial Nomenclature (MCN). We need to check to see if this EEG is one of the few in this new format. If so, certain channels need to be renamed back to their original names used in the 10-20 EEG montage system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the channel names are the non-standard ones seen in MCN\n",
    "alt_channels = ['T7', 'T8', 'P7', 'P8']\n",
    "\n",
    "# Get the channel names\n",
    "ch_names = raw_volts.info['ch_names']\n",
    "\n",
    "# T3 is now T7, T4 is now T8, T5 is now P7, T6 is now P8\n",
    "if any(x in ch_names for x in alt_channels):\n",
    "    print(\"Renaming channels\")\n",
    "    raw_volts.rename_channels({'T7':'T3', 'T8':'T4', 'P7':'T5', 'P8':'T6'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_volts = remove_art_ica(raw_volts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take channels needed for quantitative analysis\n",
    "### We no longer need the channels used in the ICA function such as the ECG or EMG channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channels to keep\n",
    "sub_ch = ['C3', 'C4', 'O1', 'O2', 'A1', 'A2', 'Cz', 'F3', 'F4', 'F7', 'F8',\n",
    "'Fz', 'Fp1', 'Fp2', 'P3', 'P4', 'Pz', 'T3', 'T4', 'T5', 'T6']\n",
    "\n",
    "# Pick channels\n",
    "raw_sub= raw_volts.copy().pick_channels(sub_ch)\n",
    "\n",
    "# Get channels and their indices for dictionary creation\n",
    "sub_ch_names = raw_sub.info['ch_names']\n",
    "ch_dict = {i:ch for ch, i in enumerate(sub_ch_names)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into numpy array, apply bandpass filter, and apply montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into numpy array\n",
    "raw_np = raw_sub.copy().get_data()\n",
    "\n",
    "# Apply band-pass filter\n",
    "order = 2\n",
    "low_cutoff = 0.5\n",
    "high_cutoff = 70\n",
    "b,a  = create_band_pass_filter(order,  low_cutoff, high_cutoff, sf) \n",
    "filt_data = apply_filter(raw_np, [b,a])\n",
    "\n",
    "# Apply Laplacian filter\n",
    "raw_lap = np.apply_along_axis(laplac, 0, filt_data, ch_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove artifact-heavy segments of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set epoch variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final epoch length (seconds)\n",
    "winLen = 4\n",
    "# Window size for the sliding window (seconds) - we use no overlap\n",
    "winDisp_filt = 1\n",
    "# Window size for artifact segment removal (seconds)\n",
    "winLen_filt = 1\n",
    "\n",
    "# Number of data points in each window\n",
    "bin_n = winLen_filt * sf\n",
    "# Scan duration in seconds\n",
    "scan_durn = rawraw._data.shape[1] / sf\n",
    "# Number of windows in the scan\n",
    "num_wins = math.floor((rawraw._data.shape[1]-1) / bin_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify epochs with excess noise\n",
    "### The function rejects epochs based on the RMS amplitude, the line length, and amplitude of the signal. It is based off of that as described in Saby et al. 2022 (https://doi.org/10.1093/braincomms/fcac197)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove A1 and A2 channels for epoch rejection\n",
    "rm_elects = [ch_dict['A1'],ch_dict['A2']]\n",
    "raw_lap_sub = np.delete(raw_lap, rm_elects, axis=0)\n",
    "# Get clean epochs\n",
    "inlier_epoch = epoch_rejection_saby(raw_lap_sub, sf, winDisp_filt, winLen_filt)\n",
    "\n",
    "# Main data in 1 second time bins\n",
    "epoch_ch_1sec = moving_window(raw_lap, sf, winDisp_filt, winLen_filt, num_wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of clean epochs: \", len(inlier_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event detection\n",
    "### Our custom detection method of annotations of sleep, seizures, photic stimulation, and hyperventilation only functions with an EDF file. To ensure example data is deidentified, it is in a fif file format, thus our function does not work with the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove events\n",
    "# inlier_epoch_filt = remove_events(edf_file, inlier_epoch)\n",
    "\n",
    "# For this example, we will not remove events\n",
    "inlier_epoch_filt = inlier_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine clean sequences into 4 second epochs and place into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract clean sequences\n",
    "sequences = extract_sequences(inlier_epoch_filt, winLen)\n",
    "epoch_starts = [i[0] for i in sequences]\n",
    "\n",
    "# Place sequences in numpy array\n",
    "epoch_ch = np.array([np.concatenate(epoch_ch_1sec[epochs], axis=1) for epochs in sequences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframes for welch output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable for example case\n",
    "Gene = \"Control\"\n",
    "cur_pat = \"P591\"\n",
    "scandate = \"2017_07_15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for power and frequency\n",
    "col_names = ['patient', 'date', 'gene', 'frequency', 'power', 'electrode', 'epochs']\n",
    "rows = len(sub_ch_names) * 70 #257 is the number of frequencies in the welch output\n",
    "pat_eo = pd.DataFrame(index = range(rows), columns = col_names)\n",
    "pat_eo.set_axis(col_names, axis = 1, inplace = True)\n",
    "pat_eo['patient'] = cur_pat\n",
    "pat_eo['gene'] = Gene\n",
    "pat_eo['date'] = scandate\n",
    "pat_eo['epochs'] = len(epoch_starts)\n",
    "\n",
    "# Dataframe for epoch information\n",
    "col_names = ['patient', 'date', 'gene', 'n_epochs', 'epochs', 'amp_filt']\n",
    "pat_epochs = pd.DataFrame(index = range(1), columns = col_names)\n",
    "pat_epochs['patient'] = cur_pat\n",
    "pat_epochs['gene'] = Gene\n",
    "pat_epochs['date'] = scandate\n",
    "pat_epochs['n_epochs'] = len(epoch_starts)\n",
    "pat_epochs['epochs'] = ';'.join(str(i) for i in epoch_starts)\n",
    "pat_epochs['amp_filt'] = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate dominant frequency in each channel and the corresponding peak value\n",
    "for ep in range(epoch_ch.shape[1]):\n",
    "    s_index = ep*70 #70 is the number of frequencies in the welch output\n",
    "    e_index = s_index + 69\n",
    "    cur_ch = sub_ch_names[ep]\n",
    "    pat_eo.loc[s_index:e_index, 'electrode'] = cur_ch\n",
    "    ch_idx = ch_dict[cur_ch]\n",
    "    ch_np = epoch_ch[:,ch_idx,:]\n",
    "    frequencies, med_psd = calculate_median_psd(ch_np, sf)\n",
    "    mask = np.logical_and(frequencies >= 1, frequencies <= 70)\n",
    "    pxx = med_psd[mask[0:len(med_psd)]]\n",
    "    frequencies = frequencies[mask]\n",
    "    pat_eo.loc[s_index:e_index, 'frequency'] = frequencies\n",
    "    pat_eo.loc[s_index:e_index, 'power'] = pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_eo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_epochs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_eo.to_csv(\"/Users/galerp/Documents/manuscripts/QEEG/EEG_Python/control_pat_psd_test.csv\", index=False)\n",
    "pat_epochs.to_csv(\"/Users/galerp/Documents/manuscripts/QEEG/EEG_Python/pat_epochs_test.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting example\n",
    "#### Here we can view the power spectral density in the occipital electrodes. You should be able to see a clear posterior dominant rhythm in the alpha band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need plotting library\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the occipital electrodes\n",
    "occ_data = pat_eo[pat_eo['electrode'].isin(['O1', 'O2'])]\n",
    "# Ensure power is numeric\n",
    "occ_data['power'] = pd.to_numeric(occ_data['power'], errors='coerce')  # Convert to numeric and coerce errors\n",
    "occ_data['log_power'] = np.log(occ_data['power'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Filter and plot each electrode separately to assign different colors\n",
    "for electrode, color in zip(['O1', 'O2'], ['blue', 'green']):\n",
    "    subset = occ_data[occ_data['electrode'] == electrode]\n",
    "    ax.plot(subset['frequency'], subset['log_power'], label=f'Electrode {electrode}', color=color)\n",
    "\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_ylabel('Log of Power')\n",
    "ax.set_title('Log Power vs. Frequency for Electrodes O1 and O2')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tst_mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
